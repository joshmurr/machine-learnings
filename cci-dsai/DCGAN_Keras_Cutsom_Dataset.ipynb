{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN-Keras-Cutsom-Dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAjOixDCnaslL7jvdgE6xJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshmurr/machine-learnings/blob/master/cci-dsai/DCGAN_Keras_Cutsom_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1CXqrESDzz5"
      },
      "source": [
        "# DCGAN - Custom Dataset\n",
        "## Deep Convolutional GAN\n",
        "\n",
        "This is much the same as the previous notebook we looked at (still using the [official Keras DCGAN implementation](https://keras.io/examples/generative/dcgan_overriding_train_step/)) but I have some extra code at the start to allow you to make your own dataset from a YouTube video!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcXXG7NMcHAl"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gdown\n",
        "from zipfile import ZipFile\n",
        "import cv2\n",
        "import math\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CotjyJ1-ewMz",
        "outputId": "bd07b271-58a5-4097-b2bf-8d037408224d"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFQoTc66Mi4f"
      },
      "source": [
        "We have to install [YouTube-DL](https://youtube-dl.org/) via pip in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMkxqCTQif06"
      },
      "source": [
        "!pip install --upgrade --quiet youtube_dl"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSx3LqLKMveN"
      },
      "source": [
        "All you need to do is to run the cell below. It just contains helper functions to download a YouTube video and to extract frames from the video to make the dataset. Feel free to poke around if you're interested."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCo8qlByilMl"
      },
      "source": [
        "# Some helper functions we will use to make the dataset\n",
        "\n",
        "from __future__ import unicode_literals\n",
        "import youtube_dl\n",
        "\n",
        "\n",
        "class MyLogger(object):\n",
        "    def debug(self, msg):\n",
        "        pass\n",
        "\n",
        "    def warning(self, msg):\n",
        "        pass\n",
        "\n",
        "    def error(self, msg):\n",
        "        print(msg)\n",
        "\n",
        "\n",
        "def my_hook(d):\n",
        "    if d['status'] == 'finished':\n",
        "        print('Done downloading.')\n",
        "\n",
        "def download_youtube_video(_url):\n",
        "  ydl_opts = {\n",
        "      'format': '(mp4)[height>=256][height<=400]',\n",
        "      'outtmpl': '%(id)s.%(ext)s',\n",
        "      'logger': MyLogger(),\n",
        "      'progress_hooks': [my_hook],\n",
        "  }\n",
        "  with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "      result = ydl.extract_info(_url, download=True)\n",
        "\n",
        "  if 'entries' in result:\n",
        "    video = result['entries'][0]\n",
        "  else:\n",
        "    video = result\n",
        "\n",
        "  return video\n",
        "\n",
        "def analyse_video(_videoPath):\n",
        "  vidcap = cv2.VideoCapture(_videoPath)\n",
        "  success, frame = vidcap.read()\n",
        "\n",
        "  frameCount = 0\n",
        "  darkFrames = []\n",
        "  validFrames = []\n",
        "\n",
        "  while success:\n",
        "    grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    average = grey.mean(axis=0).mean(axis=0)\n",
        "\n",
        "    if average < 2:\n",
        "      darkFrames.append(frameCount)\n",
        "    else:\n",
        "      validFrames.append(frameCount)\n",
        "    \n",
        "    success, frame = vidcap.read()\n",
        "    frameCount += 1\n",
        "  \n",
        "  print(f'Found {len(darkFrames)} dark frames.')\n",
        "  return validFrames, darkFrames\n",
        "\n",
        "def extract_frames(_videoPath, _outputPath, _num, _size):\n",
        "  SIZE = _size[0]\n",
        "  MAX = _num\n",
        "  count = 0\n",
        "  id = 0\n",
        "  validFrames, darkFrames = analyse_video(_videoPath)\n",
        "  doubles = []\n",
        "  frames = []\n",
        "\n",
        "  if MAX > len(validFrames):\n",
        "    numDoubles = MAX - len(validFrames)\n",
        "    doubles = np.random.choice(validFrames, size=numDoubles, replace=False)\n",
        "    frames = validFrames\n",
        "  else:\n",
        "    frames = np.random.choice(validFrames, size=MAX, replace=False)\n",
        "\n",
        "  vidcap = cv2.VideoCapture(_videoPath)\n",
        "  success, frame = vidcap.read()\n",
        "\n",
        "  frameHeight = frame.shape[0]\n",
        "  frameWidth = frame.shape[1]\n",
        "\n",
        "  scaleFactor = SIZE / frameHeight\n",
        "  newWidth = int(frameWidth * scaleFactor)\n",
        "  padding = int((newWidth - SIZE) / 2)\n",
        "\n",
        "  while success:\n",
        "    if count in frames:\n",
        "      frame = cv2.resize(frame, (newWidth, SIZE), interpolation=cv2.INTER_AREA)\n",
        "      crops = []\n",
        "\n",
        "      if count in doubles:\n",
        "        crops = [frame[0:SIZE, 0:SIZE],\n",
        "                frame[0:SIZE, padding*2:SIZE+padding*2]]\n",
        "      else:\n",
        "        crops = [frame[0:SIZE, padding:SIZE+padding]]\n",
        "\n",
        "      for crop in crops:\n",
        "        try:\n",
        "          cv2.imwrite(os.path.join(_outputPath, f'{id:04}.jpg'), crop)\n",
        "          id += 1\n",
        "        except:\n",
        "          print(\"Error saving frame.\")\n",
        "          pass\n",
        "    \n",
        "    count += 1\n",
        "    success, frame = vidcap.read()\n",
        "\n",
        "  print(f\"Saved {id} images from video '{videoInfo['title']}'\")\n",
        "\n",
        "  return id"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbvkuYrrKMZ8"
      },
      "source": [
        "# Choose a YouTube Video\n",
        "\n",
        "Find a video on YouTube which is about 4-10 minutes long. The video can be anything but ideally it will be generally consistent throughout. So timelapse video are perfect, [like this video of clouds forming](https://www.youtube.com/watch?v=NJfI_GaEyJw), or [this video of life underwater](https://www.youtube.com/watch?v=J2BKd5e15Jc) has nice consistent colours and forms. However it is entirely up to you, maybe it would be interesting to get a random video of Lady Gaga dresses.. who knows!\n",
        "\n",
        "Paste the YouTube video URL in the cell below, __replacing the url that is between the single quotes__.\n",
        "\n",
        "If the URL is long like this:\n",
        "\n",
        "```\n",
        "https://www.youtube.com/watch?v=NJfI_GaEyJw&ab_channel=wizard327\n",
        "                                           ^\n",
        "                       We don't need the stuff after this & symbol.\n",
        "```\n",
        "\n",
        "just trim the end off after (and including) the '__&__' symbol."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoIgi2xYisel",
        "outputId": "7830d51b-807f-4655-d064-93f9b311a432"
      },
      "source": [
        "url = 'https://www.youtube.com/watch?v=J2BKd5e15Jc' # Coral Reef\n",
        "videoInfo = download_youtube_video(url)\n",
        "videoFile = \"{0}.{1}\".format(videoInfo['webpage_url'].split('=')[-1], videoInfo['ext'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done downloading.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_-OFQLWL-U8"
      },
      "source": [
        "If your video has an intro and an outro we can trim that off! Change the `startTime` and `endTime` values below. The values need to be in seconds, so if the good bit of the video start at 38 seconds then enter `38` for `startTime`. If the end credits start at 9:14, then an easy way to find the seconds is `(9*60)+14`.\n",
        "\n",
        "__If you don't need to trim the video down then just don't run the cell below.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m61KiSm-iugQ",
        "outputId": "552455e0-3738-454f-cca1-c051d0036d39"
      },
      "source": [
        "# Optional trimming of the video to remove intro / end credits.\n",
        "# Skip this if your video does not need trimming.\n",
        "\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "\n",
        "def trim_video(_video, _start, _end):\n",
        "  trimmedVideo = f\"trimmed.{videoInfo['ext']}\"\n",
        "  ffmpeg_extract_subclip(videoFile, _start, _end, targetname=trimmedVideo)\n",
        "  return trimmedVideo\n",
        "\n",
        "\n",
        "startTime = 38\n",
        "endTime = (9*60)+14\n",
        "videoFile = trim_video(videoFile, startTime, endTime)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i J2BKd5e15Jc.mp4 -ss 38.00 -t 516.00 -vcodec copy -acodec copy trimmed.mp4\n",
            "... command successful.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWdv0dpWN7Gh"
      },
      "source": [
        "Next we make some directories and extract 3000 images from the the video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRHTno-9cMG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8427379e-a0a6-45c3-f0f1-a25e3d00cce9"
      },
      "source": [
        "DATASET_DIR = 'dataset'\n",
        "IMAGES_DIR = f\"{DATASET_DIR}/images\"\n",
        "OUTPUT_DIR = 'output'\n",
        "IMAGE_SIZE =(64, 64)\n",
        "try:\n",
        "  os.makedirs(DATASET_DIR)\n",
        "  os.makedirs(IMAGES_DIR)\n",
        "  os.makedirs(OUTPUT_DIR)\n",
        "except:\n",
        "  pass\n",
        "NUM_IMAGES = extract_frames(f\"/content/{videoFile}\", IMAGES_DIR, 3000, IMAGE_SIZE)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 31 dark frames.\n",
            "Saved 3000 images from video 'Exploring the Coral Reef: Learn about Oceans for Kids - FreeSchool'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcVHKvapOCSa"
      },
      "source": [
        "As with before we then turn it into a _Tensorflow dataset_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEpCzNfCc0_7",
        "outputId": "da4b0d75-865f-455d-d680-f9553dd711bb"
      },
      "source": [
        "dataset = keras.preprocessing.image_dataset_from_directory(\n",
        "    DATASET_DIR, label_mode=None, image_size=IMAGE_SIZE, batch_size=32\n",
        ")\n",
        "dataset = dataset.map(lambda x: x / 255.0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3000 files belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28RcFXw8OGsY"
      },
      "source": [
        "All things going well, if you run the cell below you should see frames from the video you chose being taken from the dataset we created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "DNOYzTQac1od",
        "outputId": "804f1852-9f1c-4544-8962-95598dcf0626"
      },
      "source": [
        "for x in dataset:\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
        "    break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahot01TYOOKW"
      },
      "source": [
        "# Defining the Model\n",
        "\n",
        "This is the same as the previous example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPjWwh8CdeK8",
        "outputId": "c200c657-ca10-42f5-ac7e-acfa9ef18075"
      },
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(64, 64, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "discriminator.summary()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 64)        3136      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 128)       131200    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 8193      \n",
            "=================================================================\n",
            "Total params: 404,801\n",
            "Trainable params: 404,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve5WyO5vdhg7",
        "outputId": "580a90b0-0a51-43e7-b86d-a781f07f6284"
      },
      "source": [
        "latent_dim = 128\n",
        "\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(8 * 8 * 128),\n",
        "        layers.Reshape((8, 8, 128)),\n",
        "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "generator.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 8192)              1056768   \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 16, 16, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       524544    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 512)       2097664   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 3)         38403     \n",
            "=================================================================\n",
            "Total params: 3,979,651\n",
            "Trainable params: 3,979,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28BVDjCNdnT4"
      },
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlygRVfXdrCK"
      },
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=1, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        for i in range(self.num_img):\n",
        "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save(os.path.join(OUTPUT_DIR, \"generated_img_%03d_%d.png\" % (epoch, i)))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilBtgRC2OS6E"
      },
      "source": [
        "# Train the GAN\n",
        "\n",
        "Now our dataset is much much smaller than [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) and so this will train a lot quicker.\n",
        "\n",
        "Unfortunately Keras likes to output a lot of it's own information during training which makes it difficult to display images using `imshow` or something similar. But as with before images from the generator are saved to a directory called `output` which you can find in the file explorer on the left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjCwDPALdtgA",
        "outputId": "a24b64d8-bb14-4ee7-e69a-e2e0d13f5dc1"
      },
      "source": [
        "epochs = 1\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=1, latent_dim=latent_dim)]\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 46s 153ms/step - d_loss: 0.5309 - g_loss: 1.0842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f35f006a490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0tPBlhsI5vm"
      },
      "source": [
        "# Extra: Saving a Model\n",
        "\n",
        "It's nice to be able to hold on to a model you've saved so you can use it at a later date. Keras (and most ML frameworks) makes this pretty easy for you.\n",
        "\n",
        "First we make a new directory to save the model into. We only really care about the generator of our can (it's the bit that makes the images after all) so we access the generator from our GAN _object_ and call `.save(< directory >)` on that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RFwq3AyHiAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff2f58a9-c6ee-457c-943f-128c8b3201d1"
      },
      "source": [
        "# Make a new directory to save the model into\n",
        "try:\n",
        "  MODEL_DIR_NAME = 'model'\n",
        "  os.mkdir(MODEL_DIR_NAME)\n",
        "  gan.generator.save(MODEL_DIR_NAME) # We're just saving the generator here as that's the interesting bit!\n",
        "except:\n",
        "  print('Error making \"/model\" directory.')\n",
        "  print('Perhaps it already exists??')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MylfFrHCWof2"
      },
      "source": [
        "As soon as this Colab session ends we lose all our saved data and all the training will be lost! So best to move it straight over to your Google Drive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTQ8KHFIHzG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ae7706-e74d-4cd5-fba9-146c8eadd3c4"
      },
      "source": [
        "# Give Colab access to your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRmCwODEW4q4"
      },
      "source": [
        "I recommend making a new folder on your Drive _first_ and moving your model into that folder so you know where it is. As is it is, the cell below will just copy your trained generator to the root directory of your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9tFTa7OH8oj"
      },
      "source": [
        "# Copy the 'model' folder to your drive\n",
        "# -r means 'copy recursively' so it copies all the files and folders\n",
        "# inside the 'model' directory.\n",
        "!cp -r /content/model/ /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlmCqCj5Xe3x"
      },
      "source": [
        "# Extra: Loading a Model\n",
        "\n",
        "To load the model we just use `saved_model.load()` and put the name of the directory inside the brackets. This will load the generator we saved into a variable which we can use exactly like any other model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz9opQq8XhpP"
      },
      "source": [
        "loaded_g = tf.saved_model.load(MODEL_DIR_NAME)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqUnpzGaaqrC"
      },
      "source": [
        "May as well make a new directory to put the images into to keep things neat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DleXAF0Ze6u"
      },
      "source": [
        "LOADED_OUTPUT = 'loaded_model_output'\n",
        "\n",
        "try:\n",
        "  os.mkdir(LOADED_OUTPUT)\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcM0QKc8Z_FK"
      },
      "source": [
        "# This is so each saved image gets a unique number.\n",
        "# Run this cell only once!\n",
        "saved_images_counter = 0"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nnnb8nqY4Fm"
      },
      "source": [
        "To run the model we need to generate a latent vector Z of length and rescale the numbers a bit in order to display it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ4Qd84iYg3H"
      },
      "source": [
        "batch_size = 1\n",
        "latent_dim = 128\n",
        "latent_z = tf.random.normal(shape=(batch_size, latent_dim))\n",
        "generated_images = loaded_g(latent_z)\n",
        "generated_images *= 255\n",
        "generated_images.numpy()\n",
        "\n",
        "for i in range(batch_size):\n",
        "  img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "  img.save(os.path.join(LOADED_OUTPUT, \"%03d_%d.png\" % (saved_images_counter, i)))\n",
        "  saved_images_counter += 1"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlJmNSBaaym7"
      },
      "source": [
        "Images are now saved into '/loaded_model_output'."
      ]
    }
  ]
}